<!doctype html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width,initial-scale=1">
<meta name="generator" content="Docusaurus v2.0.0-alpha.70">
<link rel="alternate" type="application/rss+xml" href="/blog/rss.xml" title="One Step Blog RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/blog/atom.xml" title="One Step Blog Atom Feed"><title data-react-helmet="true">K-Means | One Step</title><meta data-react-helmet="true" name="twitter:card" content="summary_large_image"><meta data-react-helmet="true" name="docusaurus_locale" content="en"><meta data-react-helmet="true" name="docusaurus_version" content="current"><meta data-react-helmet="true" name="docusaurus_tag" content="docs-default-current"><meta data-react-helmet="true" name="og:description" content="A community-led, open-sourced, e-learning platform for Machine Learning and Data Science, developed with ❤️ at elecTRON."><meta data-react-helmet="true" name="og:title" content="OneStep - ML"><meta data-react-helmet="true" name="og:site_name" content="A community-led, open-sourced, e-learning platform for Machine Learning and Data Science, developed with ❤️ at elecTRON."><meta data-react-helmet="true" property="og:title" content="K-Means | One Step"><meta data-react-helmet="true" name="description" content="K-Means clustering or simply clustering is an unsupervised learning technique. Unlike all the other techniques, which all came under supervised learning techniques, Kmeans is considered as unsupervised as there is no solid ground truth to compare our output with. It can only help us to determine the structure of our data and find smaller groups of data within our main data set."><meta data-react-helmet="true" property="og:description" content="K-Means clustering or simply clustering is an unsupervised learning technique. Unlike all the other techniques, which all came under supervised learning techniques, Kmeans is considered as unsupervised as there is no solid ground truth to compare our output with. It can only help us to determine the structure of our data and find smaller groups of data within our main data set."><meta data-react-helmet="true" property="og:url" content="https://onestep-electron.github.io/docs/EasyTrack/k-means"><link data-react-helmet="true" rel="shortcut icon" href="/img/favicon.ico"><link data-react-helmet="true" rel="canonical" href="https://onestep-electron.github.io/docs/EasyTrack/k-means"><link rel="stylesheet" href="/styles.0dd56308.css">
<link rel="preload" href="/styles.7af55a99.js" as="script">
<link rel="preload" href="/runtime~main.640c4f9f.js" as="script">
<link rel="preload" href="/main.e42dd08f.js" as="script">
<link rel="preload" href="/1.0cd6a2a7.js" as="script">
<link rel="preload" href="/32.16dae970.js" as="script">
<link rel="preload" href="/33.a55d2327.js" as="script">
<link rel="preload" href="/935f2afb.3e9ff979.js" as="script">
<link rel="preload" href="/31.310479de.js" as="script">
<link rel="preload" href="/1d4902d5.f613ce7a.js" as="script">
</head>
<body>
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){var t=null;try{t=localStorage.getItem("theme")}catch(t){}return t}();t(null!==e?e:"light")}()</script><div id="__docusaurus">
<nav aria-label="Skip navigation links"><button type="button" tabindex="0" class="skipToContent_11B0">Skip to main content</button></nav><nav class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><div aria-label="Navigation bar toggle" class="navbar__toggle" role="button" tabindex="0"><svg aria-label="Menu" width="30" height="30" viewBox="0 0 30 30" role="img" focusable="false"><title>Menu</title><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></div><a class="navbar__brand" href="/"><img src="/img/logo-allblack-half.png" alt="onestep-logo" class="themedImage_YANc themedImage--light_3CMI navbar__logo"><img src="/img/logo-allblack-half.png" alt="onestep-logo" class="themedImage_YANc themedImage--dark_3ARp navbar__logo"><strong class="navbar__title">One Step</strong></a><a class="navbar__item navbar__link" href="/docs/machine-learning-tracks">ML Tracks</a><a class="navbar__item navbar__link" href="/docs/python-crash-course">Python Crash Course</a></div><div class="navbar__items navbar__items--right"><a href="https://github.com/OneStep-elecTRON/onestep-electron.github.io" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub</a><a class="navbar__item navbar__link" href="/me">My Account</a><div class="react-toggle react-toggle--disabled displayOnlyInLargeViewport_2N3Q"><div class="react-toggle-track"><div class="react-toggle-track-check"><span class="toggle_3NWk">🌜</span></div><div class="react-toggle-track-x"><span class="toggle_3NWk">🌞</span></div></div><div class="react-toggle-thumb"></div><input type="checkbox" disabled="" aria-label="Dark mode toggle" class="react-toggle-screenreader-only"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div><div class="navbar-sidebar"><div class="navbar-sidebar__brand"><a class="navbar__brand" href="/"><img src="/img/logo-allblack-half.png" alt="onestep-logo" class="themedImage_YANc themedImage--light_3CMI navbar__logo"><img src="/img/logo-allblack-half.png" alt="onestep-logo" class="themedImage_YANc themedImage--dark_3ARp navbar__logo"><strong class="navbar__title">One Step</strong></a></div><div class="navbar-sidebar__items"><div class="menu"><ul class="menu__list"><li class="menu__list-item"><a class="menu__link" href="/docs/machine-learning-tracks">ML Tracks</a></li><li class="menu__list-item"><a class="menu__link" href="/docs/python-crash-course">Python Crash Course</a></li><li class="menu__list-item"><a href="https://github.com/OneStep-elecTRON/onestep-electron.github.io" target="_blank" rel="noopener noreferrer" class="menu__link">GitHub</a></li><li class="menu__list-item"><a class="menu__link" href="/me">My Account</a></li></ul></div></div></div></nav><div class="main-wrapper"><div class="docPage_vMrn"><div class="docSidebarContainer_3Ak5" role="complementary"><div class="sidebar_3gvy"><div class="menu menu--responsive thin-scrollbar menu_1yIk"><button aria-label="Open Menu" aria-haspopup="true" class="button button--secondary button--sm menu__button" type="button"><svg aria-label="Menu" class="sidebarMenuIcon_1CUI" width="24" height="24" viewBox="0 0 30 30" role="img" focusable="false"><title>Menu</title><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><ul class="menu__list"><li class="menu__list-item menu__list-item--collapsed"><a class="menu__link menu__link--sublist" href="#!">Introduction</a><ul class="menu__list"><li class="menu__list-item"><a class="menu__link" tabindex="-1" href="/docs/machine-learning-tracks">Introduction</a></li></ul></li><li class="menu__list-item menu__list-item--collapsed"><a class="menu__link menu__link--sublist" href="#!">PyData Tutorials</a><ul class="menu__list"><li class="menu__list-item"><a class="menu__link" tabindex="-1" href="/docs/PyDataTutorials/numpy">NumPy</a></li><li class="menu__list-item"><a class="menu__link" tabindex="-1" href="/docs/PyDataTutorials/pandas">Pandas</a></li><li class="menu__list-item"><a class="menu__link" tabindex="-1" href="/docs/PyDataTutorials/matplotlib">Matplotlib</a></li><li class="menu__list-item"><a class="menu__link" tabindex="-1" href="/docs/PyDataTutorials/seaborn">Seaborn</a></li></ul></li><li class="menu__list-item"><a class="menu__link menu__link--sublist menu__link--active" href="#!">Easy Track</a><ul class="menu__list"><li class="menu__list-item"><a class="menu__link" tabindex="0" href="/docs/EasyTrack/">Introduction</a></li><li class="menu__list-item"><a class="menu__link" tabindex="0" href="/docs/EasyTrack/linear-regression">Linear Regression</a></li><li class="menu__list-item"><a class="menu__link" tabindex="0" href="/docs/EasyTrack/logistic-regression">Logistic Regression</a></li><li class="menu__list-item"><a class="menu__link" tabindex="0" href="/docs/EasyTrack/decision-tree">Decision Tree</a></li><li class="menu__list-item"><a class="menu__link" tabindex="0" href="/docs/EasyTrack/knn">K-Nearest Neighbors (KNN)</a></li><li class="menu__list-item"><a class="menu__link" tabindex="0" href="/docs/EasyTrack/random-forest">Random Forest</a></li><li class="menu__list-item"><a class="menu__link" tabindex="0" href="/docs/EasyTrack/svm">Support Vector Machine (SVM)</a></li><li class="menu__list-item"><a aria-current="page" class="menu__link menu__link--active active" tabindex="0" href="/docs/EasyTrack/k-means">K-Means</a></li></ul></li><li class="menu__list-item menu__list-item--collapsed"><a class="menu__link menu__link--sublist" href="#!">Intermediate Track</a><ul class="menu__list"><li class="menu__list-item"><a class="menu__link" tabindex="-1" href="/docs/IntermediateTrack/">Introduction</a></li></ul></li><li class="menu__list-item menu__list-item--collapsed"><a class="menu__link menu__link--sublist" href="#!">Advanced Track</a><ul class="menu__list"><li class="menu__list-item"><a class="menu__link" tabindex="-1" href="/docs/AdvancedTrack/">Introduction</a></li></ul></li></ul></div></div></div><main class="docMainContainer_2iGs"><div class="container padding-vert--lg docItemWrapper_1bxp"><div class="row"><div class="col docItemCol_U38p"><div class="docItemContainer_a7m4"><article><header><h1 class="docTitle_Oumm">K-Means</h1></header><div class="markdown"><p>K-Means clustering or simply clustering is an unsupervised learning technique. Unlike all the other techniques, which all came under supervised learning techniques, Kmeans is considered as unsupervised as there is no solid ground truth to compare our output with. It can only help us to determine the structure of our data and find smaller groups of data within our main data set. <br></p><p>The main goal is to divide our data into sub categories or clusters or we can say  K pre-defined clusters. But how exactly do we create these clusters? Kmeans checks the similarities between different points and groups them in clusters. Remember the Euclidean distance that we discussed in KNN? We apply the same concept here as well in order to form our clusters. Let&#x27;s understand the working using an example.<br></p><p align="center"><img src="https://raw.githubusercontent.com/OneStep-elecTRON/ContentSection/main/Courses/easy_track/KMeans/KMeans-1.png" alt="drawing" width="700"></p><p>Let&#x27;s say we are given a table with heights and weights of students and we need to perform clustering on it. In the above image we have 3 rows and 2 columns. We take the first point which forms our cluster one and we then take our second point which forms our second cluster. Now, when we bring in the third row entries, we need to check in which cluster does it belong, for that purpose we will be using our K1 which is our first point and K2 which is our second point and find the euclidean distance between them and the new point. The new point will become part of the cluster with which it has the least euclidean distance. <br></p><p align="center"><img src="https://raw.githubusercontent.com/OneStep-elecTRON/ContentSection/main/Courses/easy_track/KMeans/KMeans-2.png" alt="drawing" width="700"></p><p>As we can see it has the least distance from K2 so it will become part of that cluster. Once we have found the cluster it belongs to , we need to recalculate the centroid for that cluster. This will give us a new centroid and whenever a new point enters, we will be using this new centroid to calculate the euclidean distance and this process goes on untill all the elements become part of some cluster. No point can be part of 2 clusters at the same time.<br></p><p>But again, how do we know what is the K value which is nothing but the optimal amount of Clusters required? For that we have something called the elbow method which helps us in selecting the optimal number of clusters. The idea is very simple. We need to calculate the sum of squared errors or SSE for each value of K in a given range. We will then plot a graph. It should look like an arm and the point where there is sudden dip in the plot or an &#x27;elbow&#x27; is present, we take that K value to be the optimal K value. As we increase K value, the SSE tends to 0. So the goal is to choose a small value of K which also gives us a small SSE. We have already implemented this for you in the notebook below so you may go through them to understand it&#x27;s implementation.<br></p><p>Let&#x27;s quickly summarise what we just learnt:</p><ul><li>KMeans is a unsupervised learning technique.</li><li>When we are trying to cluster our data points, we first set some random number of clusters or some random K value. And assign some centroids.</li><li>Whenever we get a new point, we calculate the Euclidean distance between these points and the one that gives least euclidean distance, the new point will belong to that cluster.</li><li>We then need to determine the new centroid of the cluster in which we add our target point. </li><li>We repeat this for any new point that we have in our plane.</li><li>To determine the optimal K value we can make use of elbow method to get better clusters.</li></ul><p>With this we come to an end to the theory related to KMeans, you might go on to the Notebooks section followed by the Hand-On activity. <br></p><div class="admonition admonition-tip alert alert--success"><div class="admonition-heading"><h5><span class="admonition-icon"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="16" viewBox="0 0 12 16"><path fill-rule="evenodd" d="M6.5 0C3.48 0 1 2.19 1 5c0 .92.55 2.25 1 3 1.34 2.25 1.78 2.78 2 4v1h5v-1c.22-1.22.66-1.75 2-4 .45-.75 1-2.08 1-3 0-2.81-2.48-5-5.5-5zm3.64 7.48c-.25.44-.47.8-.67 1.11-.86 1.41-1.25 2.06-1.45 3.23-.02.05-.02.11-.02.17H5c0-.06 0-.13-.02-.17-.2-1.17-.59-1.83-1.45-3.23-.2-.31-.42-.67-.67-1.11C2.44 6.78 2 5.65 2 5c0-2.2 2.02-4 4.5-4 1.22 0 2.36.42 3.22 1.19C10.55 2.94 11 3.94 11 5c0 .66-.44 1.78-.86 2.48zM4 14h5c-.23 1.14-1.3 2-2.5 2s-2.27-.86-2.5-2z"></path></svg></span>Implementation Walkthrough</h5></div><div class="admonition-content"><p>Learn this section on <a href="https://colab.research.google.com/drive/1zFSwABPi-66YG-BUr7a98SrL2pQndtA_?usp=sharing" target="_blank" rel="noopener noreferrer">Google Colab.</a></p></div></div><div class="quiz_1O3N"><div class="question_1xWs">Which of the following algorithm is most sensitive to outliers?</div><div class="grid_26I6"><button class="button_1ep3">K-means clustering algorithm</button><button class="button_1ep3">K-medians clustering algorithm</button><button class="button_1ep3">K-modes clustering algorithm</button><button class="button_1ep3">K-medoids clustering algorithm</button></div></div></div></article><div class="margin-vert--xl"><div class="row"><div class="col"><a href="https://github.com/OneStep-elecTRON/onestep-electron-content" target="_blank" rel="noreferrer noopener"><svg fill="currentColor" height="1.2em" width="1.2em" preserveAspectRatio="xMidYMid meet" role="img" viewBox="0 0 40 40" class="iconEdit_2LL7"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Edit this page</a></div></div></div><div class="margin-vert--lg"><nav class="pagination-nav" aria-label="Blog list page navigation"><div class="pagination-nav__item"><a class="pagination-nav__link" href="/docs/EasyTrack/svm"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">« Support Vector Machine (SVM)</div></a></div><div class="pagination-nav__item pagination-nav__item--next"><a class="pagination-nav__link" href="/docs/IntermediateTrack/"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">Introduction »</div></a></div></nav></div></div></div><div class="col col--3"><div class="tableOfContents_2xL- thin-scrollbar"></div></div></div></div></main></div></div><footer class="footer footer--dark"><div class="container"><div class="row footer__links"><div class="col footer__col"><h4 class="footer__title">Machine Learning</h4><ul class="footer__items"><li class="footer__item"><a class="footer__link-item" href="/docs/EasyTrack/">Easy Track</a></li><li class="footer__item"><a class="footer__link-item" href="/docs/IntermediateTrack/">Intermediate Track</a></li><li class="footer__item"><a class="footer__link-item" href="/docs/AdvancedTrack/">Advanced Track</a></li></ul></div><div class="col footer__col"><h4 class="footer__title">Python</h4><ul class="footer__items"><li class="footer__item"><a class="footer__link-item" target="_blank" rel="noopener noreferrer" href="/docs/EasyTrack/docs/python-crash-course">Crash Course</a></li></ul></div><div class="col footer__col"><h4 class="footer__title">Data Science</h4><ul class="footer__items"><li class="footer__item"><a href="https://github.com/OneStep-elecTRON/onestep-electron.github.io" target="_blank" rel="noopener noreferrer" class="footer__link-item">Coming Soon</a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2021 One Step, Inc. Built with Docusaurus.</div></div></div></footer></div>
<script src="/styles.7af55a99.js"></script>
<script src="/runtime~main.640c4f9f.js"></script>
<script src="/main.e42dd08f.js"></script>
<script src="/1.0cd6a2a7.js"></script>
<script src="/32.16dae970.js"></script>
<script src="/33.a55d2327.js"></script>
<script src="/935f2afb.3e9ff979.js"></script>
<script src="/31.310479de.js"></script>
<script src="/1d4902d5.f613ce7a.js"></script>
</body>
</html>